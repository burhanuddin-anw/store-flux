
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-config
  namespace: observability
data:
  otel-collector-config.yaml: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
      jaeger:
        protocols:
          grpc:
            endpoint: 0.0.0.0:14250
          thrift_http:
            endpoint: 0.0.0.0:14268
          thrift_compact:
            endpoint: 0.0.0.0:6831
          thrift_binary:
            endpoint: 0.0.0.0:6832
      httpcheck/store-front:
        targets:
          - endpoint: http://store-front.default:80
            method: GET
        collection_interval: 30s

    processors:
      memory_limiter:
        limit_percentage: 80
        spike_limit_percentage: 25
        check_interval: 5s
      k8sattributes:
        auth_type: "serviceAccount"
        passthrough: false
        filter:
          node_from_env_var: KUBE_NODE_NAME
        extract:
          metadata:
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.deployment.name
            - k8s.namespace.name
            - k8s.node.name
            - k8s.pod.start_time
        pod_association:
          - sources:
            - from: resource_attribute
              name: k8s.pod.ip
          - sources:
            - from: resource_attribute
              name: k8s.pod.uid
          - sources:
            - from: connection

    exporters:
      # Debug exporters (keep these for troubleshooting)
      debug:
        verbosity: detailed
      
      # OTLP exporter for traces to Jaeger
      otlp/jaeger:
        endpoint: "jaeger-collector.observability.svc.cluster.local:4317"
        
        tls:
          insecure: true
      
      # Prometheus exporter for metrics
      prometheus:
        endpoint: "0.0.0.0:8889"
        
      # OpenSearch exporter for logs (if you have it)
      opensearch:
        logs_index: otel-logs
        http:
          endpoint: "https://opensearch.observability.svc.cluster.local:9200"
          tls:
            insecure_skip_verify: true

    extensions:
      health_check:
        endpoint: 0.0.0.0:13133
      
    service:
      extensions: [health_check]
      pipelines:
        traces:
          receivers: [otlp, jaeger]
          processors: [memory_limiter, k8sattributes]
          exporters: [otlp/jaeger, debug]  # Using OTLP exporter for Jaeger
        metrics:
          receivers: [otlp, httpcheck/store-front]
          processors: [memory_limiter, k8sattributes]
          exporters: [prometheus, debug]
        logs:
          receivers: [otlp]
          processors: [memory_limiter, k8sattributes]
          exporters: [opensearch, debug]  # Adjust based on your log backend

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otel-collector
  namespace: observability
spec:
  replicas: 1
  selector:
    matchLabels:
      app: otel-collector
  template:
    metadata:
      labels:
        app: otel-collector
    spec:
      serviceAccountName: otel-collector  # Make sure this service account exists
      containers:
      - name: otel-collector
        image: otel/opentelemetry-collector-contrib:0.97.0
        command:
          - "/otelcol-contrib"
          - "--config=/conf/otel-collector-config.yaml"
        volumeMounts:
        - name: otel-collector-config-vol
          mountPath: /conf
        ports:
        - containerPort: 4317   # OTLP gRPC receiver
        - containerPort: 4318   # OTLP HTTP receiver
        - containerPort: 14250  # Jaeger gRPC receiver
        - containerPort: 14268  # Jaeger HTTP receiver
        - containerPort: 6831   # Jaeger Thrift Compact UDP
        - containerPort: 6832   # Jaeger Thrift Binary UDP
        - containerPort: 8889   # Prometheus metrics endpoint
        - containerPort: 13133  # Health check endpoint
        env:
        - name: KUBE_NODE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: spec.nodeName
        resources:
          limits:
            memory: 2Gi
            cpu: 1000m
          requests:
            memory: 400Mi
            cpu: 100m
      volumes:
      - name: otel-collector-config-vol
        configMap:
          name: otel-collector-config
          items:
          - key: otel-collector-config.yaml
            path: otel-collector-config.yaml
            
---
apiVersion: v1
kind: Service
metadata:
  name: otel-collector
  namespace: observability
spec:
  ports:
  - name: otlp-grpc
    port: 4317
    targetPort: 4317
    protocol: TCP
  - name: otlp-http
    port: 4318
    targetPort: 4318
    protocol: TCP
  - name: jaeger-grpc
    port: 14250
    targetPort: 14250
    protocol: TCP
  - name: jaeger-http
    port: 14268
    targetPort: 14268
    protocol: TCP
  - name: jaeger-thrift-compact
    port: 6831
    targetPort: 6831
    protocol: UDP
  - name: jaeger-thrift-binary
    port: 6832
    targetPort: 6832
    protocol: UDP
  - name: prometheus
    port: 8889
    targetPort: 8889
    protocol: TCP
  - name: health-check
    port: 13133
    targetPort: 13133
    protocol: TCP
  selector:
    app: otel-collector
  type: ClusterIP

---
# Service Account for OTEL Collector
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otel-collector
  namespace: observability

---
# ClusterRole for accessing Kubernetes resources
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: otel-collector
  
rules:
- apiGroups: [""]
  resources: ["pods", "namespaces "]
  verbs: ["get", "list", "watch"]
- apiGroups: ["apps"]
  resources: ["replicasets", "deployments"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["extensions"]
  resources: ["replicasets"]
  verbs: ["get", "list", "watch"]

---
# ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: otel-collector
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: otel-collector
subjects:
- kind: ServiceAccount
  name: otel-collector
  namespace: observability